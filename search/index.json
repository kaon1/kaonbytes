[{"content":"A common IT Workflow exists where a Cloud provider\u0026rsquo;s public IP ranges are added to a static firewall object list. The reasons why this is done include: Network Address Translation (NAT), Access Control (ACL) or logging.\nOften times, the network engineer is unaware when the Cloud Provider updates their IP ranges and thus the IT Workflow is no longer in compliance.\nWe can automate some of this process by setting up a job to continually check the Cloud IP ranges and alert us if a change is required.\nOverview The below process is specifically for Google Cloud IP Ranges and Fortinet Firewall Objects. However, with a few tweaks can be ported to other services such as Fastly and AWS as well as other firewall vendors supported by ansible collections.\nAnsible Code compare-google-ips-check-against-fortinet.yml\n### This playbook will compare the list of known IPv4 Google Cloud IP addresses against### the a deployed \u0026#39;address_grp\u0026#39; object in a Fortigate Firewall### First we grab the json data from https://www.gstatic.com/ipranges/goog.json and extract ipv4 addresses to a list### Next we grab the firewall_addrgrp called \u0026#39;google_cdn\u0026#39; on the firewall and put it into a list### We run a difference of list1 vs list2. If there is a difference, the PB will throw an error and Tower sends email---- name:PB to compare Google Cloud IPs vs current \u0026#39;google_cdn\u0026#39; object in firewallhosts:firewall_host1gather_facts:falsevars:### Fortinet specific vars for Ansible to connect - https://galaxy.ansible.com/fortinet/fortiosansible_python_interpreter:/usr/bin/python3ansible_user:useransible_password:passwordansible_connection:httpapiansible_httpapi_use_ssl:yesansible_httpapi_validate_certs:noansible_httpapi_port:443ansible_network_os:fortinet.fortios.fortiosvdom:\u0026#34;root\u0026#34;### Variable to store list of \u0026#39;google_cdn\u0026#39; ips as a list from the user firewallgoogle_ip_list:[]### Variable to store list of Google Cloud IP addresses we retrieve from the internetgoogle_cdn_ipv4_list:[]### Variable to store the list difference resultmissing_google_ips:[]tasks:### GET request to retrieve the current json data of Google Cloud IP Ranges- name:Get all google cloud ip ranges as json resulturi:url:\u0026#34;https://www.gstatic.com/ipranges/goog.json\u0026#34;method:GETvalidate_certs:noregister:google_web_json_result### Ansible will register a change here, we can ignore it.changed_when:falsedelegate_to:localhost### Extract only IPv4 Addresses and add to a flat list- set_fact:google_cdn_ipv4_list:\u0026#34;{{ google_cdn_ipv4_list + [ item[\u0026#39;ipv4Prefix\u0026#39;] ] }}\u0026#34;loop:\u0026#34;{{ google_web_json_result.json.prefixes }}\u0026#34;when:item[\u0026#39;ipv4Prefix\u0026#39;] is definedchanged_when:falsedelegate_to:localhost### Hit the firewall once here to retrieve the object. This object does not contain IP/Mask info only names- name:Get google_cdn list of objects from firewallfortinet.fortios.fortios_configuration_fact:vdom:\u0026#34;{{ vdom }}\u0026#34;selector:\u0026#34;firewall_addrgrp\u0026#34;params:name:\u0026#34;google_cdn\u0026#34;register:google_networks_objectschanged_when:false### For each name in \u0026#39;google_cdn\u0026#39; object we ask the firewall to give us back the IP/Mask info. Many API hits here.- name:Iterate through every Google object and extract subnet infofortinet.fortios.fortios_configuration_fact:vdom:\u0026#34;{{ vdom }}\u0026#34;selector:\u0026#34;firewall_address\u0026#34;params:name:\u0026#34;{{ item.name }}\u0026#34;register:google_itemloop:\u0026#34;{{ google_networks_objects.meta.results[0][\u0026#39;member\u0026#39;] }}\u0026#34;changed_when:false### The returned IP and Subnet info is in form 10.10.10.10 255.255.255.0. These Filters translate that to 10.10.10.10/24### List is populated with all \u0026#39;google_cdn\u0026#39; IP/Mask in correct format for comparison- set_fact:google_ip_list:\u0026#34;{{ google_ip_list + [ item.meta.results[0].subnet | replace(\u0026#39; \u0026#39;,\u0026#39;/\u0026#39;) | ansible.netcommon.ipaddr ] }}\u0026#34;loop:\u0026#34;{{ google_item.results }}\u0026#34;changed_when:falsedelegate_to:localhost### Use ansible difference filter to compare list1 to list2. It shows items that are in list1 but not in list2- name:Show the difference in listsset_fact:missing_google_ips:\u0026#34;{{ google_cdn_ipv4_list | difference(google_ip_list) }}\u0026#34;changed_when:falsedelegate_to:localhost### If an IP Subnet exists in the google cdn ipv4 list but not on the firewall \u0026#39;google_cdn object\u0026#39; then### we fail the PB and Tower will send an email with the list- debug:msg:\u0026#34;List of missing Google Subnets that need to be added to Firewall: {{ missing_google_ips }}\u0026#34;failed_when:missing_google_ips | length\u0026gt;0Results  No Difference Detected:   Difference Detected:  Detailed Step-by-Step Let\u0026rsquo;s dive into the step-by-step\nGet Google Cloud IP Ranges Browsing to https://www.gstatic.com/ipranges/goog.json returns a JSON result of IP Prefixes.\nWe can programmatically access the JSON result and store all IPv4 prefixes in an ansible list called google_cdn_ipv4_list:\n### GET request to retrieve the current json data of Google Cloud IP Ranges- name:Get all google cloud ip ranges as json resulturi:url:\u0026#34;https://www.gstatic.com/ipranges/goog.json\u0026#34;method:GETvalidate_certs:noregister:google_web_json_result### Ansible will register a change here, we can ignore it.changed_when:falsedelegate_to:localhost### Extract only IPv4 Addresses and add to a flat list- set_fact:google_cdn_ipv4_list:\u0026#34;{{ google_cdn_ipv4_list + [ item[\u0026#39;ipv4Prefix\u0026#39;] ] }}\u0026#34;loop:\u0026#34;{{ google_web_json_result.json.prefixes }}\u0026#34;when:item[\u0026#39;ipv4Prefix\u0026#39;] is definedchanged_when:falsedelegate_to:localhostWe can run the above tasks and print the result. Below is a printout of each dataset: https://www.gstatic.com/ipranges/goog.json and google_cdn_ipv4_list\n   HTTP Site Ansible GET Result          Get Address Group from Fortigate We can use the ansible collection provided by Fortinet to gather facts.\nIn the below task we will retrieve the firewall address group named test_group_1\n- name:Get Fortigate Address Groupfortinet.fortios.fortios_configuration_fact:vdom:\u0026#34;root\u0026#34;selector:\u0026#34;firewall_addrgrp\u0026#34;params:name:\u0026#34;test_group_1\u0026#34;register:google_networks_objects- debug:var:google_networks_objects.meta.results[0]Here is a comparison of the Address Group in the Fortigate GUI and the Ansible Result:\n   HTTP Site         Ansible Result:\nTASK [debug] *********************ok:[localhost] =\u0026gt; {\u0026#34;google_networks_objects.meta.results[0]\u0026#34;: {\u0026#34;allow-routing\u0026#34;: \u0026#34;disable\u0026#34;,\u0026#34;color\u0026#34;: 0,\u0026#34;comment\u0026#34;: \u0026#34;\u0026#34;,\u0026#34;exclude\u0026#34;: \u0026#34;disable\u0026#34;,\u0026#34;exclude-member\u0026#34;: [],\u0026#34;member\u0026#34;: [{\u0026#34;name\u0026#34;: \u0026#34;test_net_1\u0026#34;,\u0026#34;q_origin_key\u0026#34;: \u0026#34;test_net_1\u0026#34;},{\u0026#34;name\u0026#34;: \u0026#34;test_net_2\u0026#34;,\u0026#34;q_origin_key\u0026#34;: \u0026#34;test_net_2\u0026#34;},{\u0026#34;name\u0026#34;: \u0026#34;test_net_3\u0026#34;,\u0026#34;q_origin_key\u0026#34;: \u0026#34;test_net_3\u0026#34;}],\u0026#34;name\u0026#34;: \u0026#34;test_group_1\u0026#34;,\u0026#34;q_origin_key\u0026#34;: \u0026#34;test_group_1\u0026#34;,\u0026#34;tagging\u0026#34;: [],\u0026#34;uuid\u0026#34;: \u0026#34;3ff6c462-c7f1-51ec-f405-2a6b59ee9591\u0026#34;,\u0026#34;visibility\u0026#34;: \u0026#34;enable\u0026#34;}}Get Each Member of Group The above ansible result gives us a list of address group member names. We have to query the firewall again for the IP address and subnet mask of each member.\nThis task will loop through each group member:\n- name:Iterate through every Google object and extract subnet infofortinet.fortios.fortios_configuration_fact:vdom:\u0026#34;{{ vdom }}\u0026#34;selector:\u0026#34;firewall_address\u0026#34;params:name:\u0026#34;{{ item.name }}\u0026#34;register:google_itemloop:\u0026#34;{{ google_networks_objects.meta.results[0][\u0026#39;member\u0026#39;] }}\u0026#34;- debug:var:google_itemExtract Subnet Info to List The returned results need to be parsed. The subnet field should be normalized to IP/MASK notation so that we can more easily run a diff later against the exisiting google cdn list that we grabbed earlier from the web.\nWe can parse each subnet field and transfrom it to IP/MASK notation with this task:\n- set_fact:google_ip_list:\u0026#34;{{ google_ip_list + [ item.meta.results[0].subnet | replace(\u0026#39; \u0026#39;,\u0026#39;/\u0026#39;) | ansible.netcommon.ipaddr ] }}\u0026#34;loop:\u0026#34;{{ google_item.results }}\u0026#34;changed_when:falsedelegate_to:localhostNow we have a list of all IPs from the Fortigate in a normalized view (Example Data):\nTASK [debug] *****************************ok:[localhost] =\u0026gt; {\u0026#34;google_ip_list\u0026#34;: [\u0026#34;1.1.1.0/24\u0026#34;,\u0026#34;2.2.0.0/22\u0026#34;,\u0026#34;3.3.3.0/30\u0026#34;]}Data Comparison We use the built-in ansible difference filter to compare the two lists that we have extracted.\nThis is a one-way comparison, meaning we compare Google list from the web \u0026ndash;\u0026gt; Google List from the Fortigate.\nIf we wanted a full comparison, we would run this task again in reverse.\n### Use ansible difference filter to compare list1 to list2. It shows items that are in list1 but not in list2- name:Show the difference in listsset_fact:missing_google_ips:\u0026#34;{{ google_cdn_ipv4_list | difference(google_ip_list) }}\u0026#34;changed_when:falsedelegate_to:localhost### If an IP Subnet exists in the google cdn ipv4 list but not on the firewall \u0026#39;google_cdn object\u0026#39; then### we fail the PB and Tower will send an email with the list- debug:msg:\u0026#34;List of missing Google Subnets that need to be added to Firewall: {{ missing_google_ips }}\u0026#34;failed_when:missing_google_ips | length\u0026gt;0Alerting and Scheduling We can use Ansible Tower/AWX to schedule playbook execution and alerting.\nThe playbook is set to fail if there is an IP in the web list that does not exist in the Fortigate list.\nWe do this so that Ansible Tower can alert on failure. More info on setting up Notifications here\nSimilarly, job scheduling can also be setup so the task runs daily\nWrap Up I hope this tutorial was useful to anyone looking to automate a common operational workflow. This playbook performs read actions, its a good way to get started on your automation journey without worrying about making breaking changes.\nThe next logical iteration for this process is to automatically update the firewall object without manual intervention.\nFeel free to comment below or contact me on Twitter if you have any questions.\nThanks!\n","date":"2022-04-28T00:00:00Z","image":"https://kaonbytes.com/p/use-ansible-to-compare-cloud-ip-ranges-against-firewall-object/cloud-ip-checks-mini_hudd0ab147682fbdd31b8bb756e5cdd221_351688_120x120_fill_box_smart1_3.png","permalink":"https://kaonbytes.com/p/use-ansible-to-compare-cloud-ip-ranges-against-firewall-object/","title":"Use Ansible to compare Cloud IP Ranges against Firewall object"},{"content":"The best way for a Network Engineer to grasp automation is to begin by coding a simple problem that they encounter. We often use IPERF to measure the bandwidth performance of a network path. With a few lines of python code, we can automate this task and graph the data via DataDog for historical reference.\nThe End Result Nobody likes to read through pages of text and images to get to the money shot. So here it is\u0026hellip;\nDataDog Graph Graph of hourly iperf3 tests:\nPython Code iperf-dd-metrics.py\n# Script to run iperf3 test to measure bandwidth to remote site. # Runs in reverse mode to measure both ingress and egress bandwidth # Sends avg bandwidth metric to Datadog as a custom gauge metric # Its suggested you run this script as a cron job on a regular hourly interval from datadog import initialize, statsd import time import iperf3 import os # Set vars # Remote iperf server IP remote_site = \u0026#39;\u0026lt;enter remote host IP here\u0026gt;\u0026#39; # Datadog API Key api_key = \u0026#39;\u0026lt;enter dd api key here\u0026gt;\u0026#39; # How long to run iperf3 test in seconds test_duration = 20 # Set DD options for statsd init options = { \u0026#39;statsd_host\u0026#39;: \u0026#39;127.0.0.1\u0026#39;, \u0026#39;statsd_port\u0026#39;: 8125, \u0026#39;api_key\u0026#39;: api_key } initialize(**options) # Set Iperf Client Options # Run 10 parallel streams on port 5201 for duration w/ reverse client = iperf3.Client() client.server_hostname = remote_site client.zerocopy = True client.verbose = False client.reverse = True client.port = 5201 client.num_streams = 10 client.duration = int(test_duration) client.bandwidth = 1000000000 # Run iperf3 test result = client.run() # extract relevant data sent_mbps = int(result.sent_Mbps) received_mbps = int(result.received_Mbps) # send Metrics to DD and add some tags for classification in DD GUI # send bandwidth metric - egress mbps statsd.gauge(\u0026#39;iperf3.test.mbps.egress\u0026#39;, sent_mbps, tags=[\u0026#34;team_name:your_team\u0026#34;, \u0026#34;team_app:iperf\u0026#34;]) # send bandwidth metric - ingress mbps statsd.gauge(\u0026#39;iperf3.test.mbps.ingress\u0026#39;, received_mbps, tags=[\u0026#34;team_name:your_team\u0026#34;, \u0026#34;team_app:iperf\u0026#34;]) The Process If you\u0026rsquo;re still here, let\u0026rsquo;s get into the details\u0026hellip;\nSetup  Spin up two Linux Hosts (HostA and HostB)  Install Python3 \u0026ndash;\u0026gt; yum install python3 Install IPERF3 \u0026ndash;\u0026gt; yum install iperf3 Install iPerf3 Python Wrapper \u0026ndash;\u0026gt; pip install iperf3   Setup a DataDog Account and API Key  Graphing the metrics is optional. Alternatively, we can save results to local disk.    iperf3 Server Choose one of your hosts to be your always-on iperf3 server and setup an iperf3 service in systemd\n For Centos Linux:  cd /etc/systemd/system/ Create a file called iperf3.service Contents:    # Centos Server file to run iperf3 service on startup. # This server acts as the iperf \u0026#39;receiver\u0026#39; for speed testing. # /etc/systemd/system/iperf3.service # User service: $HOME/.config/systemd/user/iperf3.service [Unit] Description=iperf3 server After=syslog.target network.target auditd.service [Service] ExecStart=/usr/bin/iperf3 -s [Install] WantedBy=multi-user.target  enable the service to run at startup: systemctl enable iperf3.service start the iperf3 service: systemctl start iperf3.service verify the service is running: systemctl status iperf3.service or ps aux | grep iperf  iperf3 Client Begin testing the iperf3 service by creating a simple python script on the Client HostA\n Create iperf-dd-metrics-test.py:  import iperf3 # Set vars # Remote iperf server IP remote_site = \u0026#39;ip of server goes here\u0026#39; # How long to run iperf3 test in seconds test_duration = 10 # Set Iperf Client Options # Run 10 parallel streams on port 5201 for duration w/ reverse client = iperf3.Client() client.server_hostname = remote_site client.zerocopy = True client.verbose = False client.reverse = True client.port = 5201 client.num_streams = 10 client.duration = int(test_duration) client.bandwidth = 1000000000 # Run iperf3 test result = client.run() # extract relevant data sent_mbps = int(result.sent_Mbps) received_mbps = int(result.received_Mbps) print(\u0026#39;sent_mbps: \u0026#39;) print(sent_mbps) print(\u0026#39;received_mbps: \u0026#39;) print(received_mbps)  run the file: # python3 iperf-dd-metrics-test.py:  results:  sent_mbps: 966 received_mbps: 959   Now we have a fully functioning iperf3 client and server setup.\nSending Metrics to DataDog DataDog has a python library to allow us to send the speed test results up to DD\n Import the library and initialize options:  from datadog import initialize, statsd # Datadog API Key api_key = os.getenv(\u0026#39;DD_API_KEY\u0026#39;) # Set DD options for statsd init options = { \u0026#39;statsd_host\u0026#39;: \u0026#39;127.0.0.1\u0026#39;, \u0026#39;statsd_port\u0026#39;: 8125, \u0026#39;api_key\u0026#39;: api_key } initialize(**options) # send Metrics to DD and add some tags for classification in DD GUI # send bandwidth metric - egress mbps statsd.gauge(\u0026#39;iperf3.test.mbps.egress\u0026#39;, sent_mbps, tags=[\u0026#34;team_name:your_team\u0026#34;, \u0026#34;team_app:iperf\u0026#34;]) # send bandwidth metric - ingress mbps statsd.gauge(\u0026#39;iperf3.test.mbps.ingress\u0026#39;, received_mbps, tags=[\u0026#34;team_name:your_team\u0026#34;, \u0026#34;team_app:iperf\u0026#34;]) Full Script and Crontab Put the two pieces of the script together and you get the end result \u0026mdash; iperf-dd-metrics.py\nUse crontab to continuously run the script in periodic intervals.\n# Example of job definition: # .---------------- minute (0 - 59) # | .------------- hour (0 - 23) # | | .---------- day of month (1 - 31) # | | | .------- month (1 - 12) OR jan,feb,mar,apr ... # | | | | .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat # | | | | | # * * * * * user-name command to be executed 20 * * * * root /usr/bin/python3 /home/iperf-python/iperf-dd-metrics.py The above job will run every hour on the 20th minute of the hour forever\nVisualizing the Data The metrics that are being sent to DataDog need to be graphed on a dashboard\n Logon to DataDog and go to Metrics \u0026ndash;\u0026gt; Explorer Search iperf3 Find you metrics   Create a timeseries graph Graph both Egress and Ingress Metrics as A and B respectively Set your Y-Axis to desired MAX setting (999 in my case) Give your graph a title  Final Thoughts This scenario is a good way to get started with network automation. However, it can be iterated and improved by:\n Adding more metrics:  Jitter Packet Loss UDP Testing   Add exception handling  Feel free to contact me on twitter or comment below if you need help. Cheers!\n","date":"2022-04-14T00:00:00Z","image":"https://kaonbytes.com/p/automate-network-bandwidth-testing-with-python-and-iperf/python-iperf-datadog-mini2_hu779ac677055344eb65e39a4877c2e8ce_279163_120x120_fill_box_smart1_3.png","permalink":"https://kaonbytes.com/p/automate-network-bandwidth-testing-with-python-and-iperf/","title":"Automate Network Bandwidth Testing with Python and Iperf"}]